Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	combine_end_segment
	25	organize_one_chrom_end_raw
	25	rid_overlapping_from_raw
	52

[Fri Apr  2 14:24:28 2021]
rule organize_one_chrom_end_raw:
    input: ../../../ROADMAP_aligned_reads/chromHMM_model/model_100_state/mm10_segmentations/Mm10_100_raw_segments.bed.gz
    output: temp_raw_end_chr_22.gz
    jobid: 31
    wildcards: chrom=22

[Fri Apr  2 14:24:28 2021]
Finished job 31.
1 of 52 steps (2%) done

[Fri Apr  2 14:24:28 2021]
rule rid_overlapping_from_raw:
    input: temp_raw_end_chr_22.gz
    output: temp_remove_indices_chr_22.gz
    jobid: 8
    wildcards: chrom=22

[Fri Apr  2 14:24:30 2021]
Error in rule rid_overlapping_from_raw:
    jobid: 8
    output: temp_remove_indices_chr_22.gz

RuleException:
CalledProcessError in line 63 of /u/project/ernst/havu73/source/chromHMM_utilities/liftOver/Snakefile:
Command ' set -euo pipefail;  
		pypy find_overlapping_segments_from_liftOver_one_chrom.py temp_raw_end_chr_22.gz temp_remove_indices_chr_22.gz ' returned non-zero exit status 1.
  File "/u/project/ernst/havu73/source/chromHMM_utilities/liftOver/Snakefile", line 63, in __rule_rid_overlapping_from_raw
  File "/u/home/h/havu73/project-ernst/anaconda/envs/zane_env/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Removing output files of failed job rid_overlapping_from_raw since they might be corrupted:
temp_remove_indices_chr_22.gz
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /u/project/ernst/havu73/source/chromHMM_utilities/liftOver/.snakemake/log/2021-04-02T142427.012464.snakemake.log
